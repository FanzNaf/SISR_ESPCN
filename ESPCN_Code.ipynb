{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FanzNaf/SISR_ESPCN/blob/main/ESPCN_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSIOX9FkHia1"
      },
      "source": [
        "# **Mount drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kGW-_MQ5qf-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64c60f1-8e35-4045-b6da-90fb28da1e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qFuIBWYtEA-"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LcU9BP0LoZ6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92aba52e-501a-414c-8f11-3c0a5d493ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ESPCN-Pytorch'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 336 (delta 1), reused 1 (delta 1), pack-reused 333\u001b[K\n",
            "Receiving objects: 100% (336/336), 49.32 MiB | 36.10 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Nhat-Thanh/ESPCN-Pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aCxs66QIs9JU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ded34ea-c2d1-4d37-d607-634715b64e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ESPCN-Pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd /content/ESPCN-Pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcFmW-Z2xpt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42215e0-af35-4f96-b009-538932e9bbc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NNnil1fwpvPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a88146-ce1d-408f-fbe0-d17eee39d689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset/train/im_001.png\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "dataset/train/im_002.png\n",
            "dataset/train/im_003.png\n",
            "dataset/train/im_004.png\n",
            "dataset/train/im_005.png\n",
            "dataset/train/im_006.png\n",
            "dataset/train/im_007.png\n",
            "dataset/train/im_008.png\n",
            "dataset/train/im_009.png\n",
            "dataset/train/im_010.png\n",
            "dataset/train/im_011.png\n",
            "dataset/train/im_012.png\n",
            "dataset/train/im_013.png\n",
            "dataset/train/im_014.png\n",
            "dataset/train/im_015.png\n",
            "dataset/train/im_016.png\n",
            "dataset/train/im_017.png\n",
            "dataset/train/im_018.png\n",
            "dataset/train/im_019.png\n",
            "dataset/train/im_020.png\n",
            "dataset/train/im_021.png\n",
            "dataset/train/im_022.png\n",
            "dataset/train/im_023.png\n",
            "dataset/train/im_024.png\n",
            "dataset/train/im_025.png\n",
            "dataset/train/im_026.png\n",
            "dataset/train/im_027.png\n",
            "dataset/train/im_028.png\n",
            "dataset/train/im_029.png\n",
            "dataset/train/im_030.png\n",
            "dataset/train/im_031.png\n",
            "dataset/train/im_032.png\n",
            "dataset/train/im_033.png\n",
            "dataset/train/im_034.png\n",
            "dataset/train/im_035.png\n",
            "dataset/train/im_036.png\n",
            "dataset/train/im_037.png\n",
            "dataset/train/im_038.png\n",
            "dataset/train/im_039.png\n",
            "dataset/train/im_040.png\n",
            "dataset/train/im_041.png\n",
            "dataset/train/im_042.png\n",
            "dataset/train/im_043.png\n",
            "dataset/train/im_044.png\n",
            "dataset/train/im_045.png\n",
            "dataset/train/im_046.png\n",
            "dataset/train/im_047.png\n",
            "dataset/train/im_048.png\n",
            "dataset/train/im_049.png\n",
            "dataset/train/im_050.png\n",
            "dataset/train/im_051.png\n",
            "dataset/train/im_052.png\n",
            "dataset/train/im_053.png\n",
            "dataset/train/im_054.png\n",
            "dataset/train/im_055.png\n",
            "dataset/train/im_056.png\n",
            "dataset/train/im_057.png\n",
            "dataset/train/im_058.png\n",
            "dataset/train/im_059.png\n",
            "dataset/train/im_060.png\n",
            "dataset/train/im_061.png\n",
            "dataset/train/im_062.png\n",
            "dataset/train/im_063.png\n",
            "dataset/train/im_064.png\n",
            "dataset/train/im_065.png\n",
            "dataset/train/im_066.png\n",
            "dataset/train/im_067.png\n",
            "dataset/train/im_068.png\n",
            "dataset/train/im_069.png\n",
            "dataset/train/im_070.png\n",
            "dataset/train/im_071.png\n",
            "dataset/train/im_072.png\n",
            "dataset/train/im_073.png\n",
            "dataset/train/im_074.png\n",
            "dataset/train/im_075.png\n",
            "dataset/train/im_076.png\n",
            "dataset/train/im_077.png\n",
            "dataset/train/im_078.png\n",
            "dataset/train/im_079.png\n",
            "dataset/train/im_080.png\n",
            "dataset/train/im_081.png\n",
            "dataset/train/im_082.png\n",
            "dataset/train/im_083.png\n",
            "dataset/train/im_084.png\n",
            "dataset/train/im_085.png\n",
            "dataset/train/im_086.png\n",
            "dataset/train/im_087.png\n",
            "dataset/train/im_088.png\n",
            "dataset/train/im_089.png\n",
            "dataset/train/im_090.png\n",
            "dataset/train/im_091.png\n",
            "dataset/train/im_092.png\n",
            "dataset/train/im_093.png\n",
            "dataset/train/im_094.png\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ESPCN-Pytorch/train.py\", line 54, in <module>\n",
            "    train_set.generate(lr_crop_size, hr_crop_size)\n",
            "  File \"/content/ESPCN-Pytorch/utils/dataset.py\", line 38, in generate\n",
            "    subim_data = gaussian_blur(subim_label, sigma=0.7)\n",
            "  File \"/content/ESPCN-Pytorch/utils/common.py\", line 70, in gaussian_blur\n",
            "    blur_image = transforms.GaussianBlur(kernel_size=ksize, sigma=sigma)(src)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\", line 1819, in forward\n",
            "    return F.gaussian_blur(img, self.kernel_size, [sigma, sigma])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\", line 1386, in gaussian_blur\n",
            "    output = F_t.gaussian_blur(t_img, kernel_size, sigma)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\", line 753, in gaussian_blur\n",
            "    kernel = _get_gaussian_kernel2d(kernel_size, sigma, dtype=dtype, device=img.device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\", line 741, in _get_gaussian_kernel2d\n",
            "    kernel1d_y = _get_gaussian_kernel1d(kernel_size[1], sigma[1]).to(device, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\", line 731, in _get_gaussian_kernel1d\n",
            "    pdf = torch.exp(-0.5 * (x / sigma).pow(2))\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Train with scale x2\n",
        "!rm -rf dataset/*.npy\n",
        "!python train.py  --steps=300000              \\\n",
        "                  --scale=2                   \\\n",
        "                  --batch_size=128            \\\n",
        "                  --save-best-only=0          \\\n",
        "                  --save-every=1000           \\\n",
        "                  --save-log=0                \\\n",
        "                  --ckpt-dir=\"checkpoint/x2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8IamtstajgzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6234e4be-42c6-4aff-db80-02717f7ca871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset/train/im_001.png\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "dataset/train/im_002.png\n",
            "dataset/train/im_003.png\n",
            "dataset/train/im_004.png\n",
            "dataset/train/im_005.png\n",
            "dataset/train/im_006.png\n",
            "dataset/train/im_007.png\n",
            "dataset/train/im_008.png\n",
            "dataset/train/im_009.png\n",
            "dataset/train/im_010.png\n",
            "dataset/train/im_011.png\n",
            "dataset/train/im_012.png\n",
            "dataset/train/im_013.png\n",
            "dataset/train/im_014.png\n",
            "dataset/train/im_015.png\n",
            "dataset/train/im_016.png\n",
            "dataset/train/im_017.png\n",
            "dataset/train/im_018.png\n",
            "dataset/train/im_019.png\n",
            "dataset/train/im_020.png\n",
            "dataset/train/im_021.png\n",
            "dataset/train/im_022.png\n",
            "dataset/train/im_023.png\n",
            "dataset/train/im_024.png\n",
            "dataset/train/im_025.png\n",
            "dataset/train/im_026.png\n",
            "dataset/train/im_027.png\n",
            "dataset/train/im_028.png\n",
            "dataset/train/im_029.png\n",
            "dataset/train/im_030.png\n",
            "dataset/train/im_031.png\n",
            "dataset/train/im_032.png\n",
            "dataset/train/im_033.png\n",
            "dataset/train/im_034.png\n",
            "dataset/train/im_035.png\n",
            "dataset/train/im_036.png\n",
            "dataset/train/im_037.png\n",
            "dataset/train/im_038.png\n",
            "dataset/train/im_039.png\n",
            "dataset/train/im_040.png\n",
            "dataset/train/im_041.png\n",
            "dataset/train/im_042.png\n",
            "dataset/train/im_043.png\n",
            "dataset/train/im_044.png\n",
            "dataset/train/im_045.png\n",
            "dataset/train/im_046.png\n",
            "dataset/train/im_047.png\n",
            "dataset/train/im_048.png\n",
            "dataset/train/im_049.png\n",
            "dataset/train/im_050.png\n",
            "dataset/train/im_051.png\n",
            "dataset/train/im_052.png\n",
            "dataset/train/im_053.png\n",
            "dataset/train/im_054.png\n",
            "dataset/train/im_055.png\n",
            "dataset/train/im_056.png\n",
            "dataset/train/im_057.png\n",
            "dataset/train/im_058.png\n",
            "dataset/train/im_059.png\n",
            "dataset/train/im_060.png\n",
            "dataset/train/im_061.png\n",
            "dataset/train/im_062.png\n",
            "dataset/train/im_063.png\n",
            "dataset/train/im_064.png\n",
            "dataset/train/im_065.png\n",
            "dataset/train/im_066.png\n",
            "dataset/train/im_067.png\n",
            "dataset/train/im_068.png\n",
            "dataset/train/im_069.png\n",
            "dataset/train/im_070.png\n",
            "dataset/train/im_071.png\n",
            "dataset/train/im_072.png\n",
            "dataset/train/im_073.png\n",
            "dataset/train/im_074.png\n",
            "dataset/train/im_075.png\n",
            "dataset/train/im_076.png\n",
            "dataset/train/im_077.png\n",
            "dataset/train/im_078.png\n",
            "\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Train with scale x3\n",
        "!rm -rf dataset/*.npy\n",
        "!python train.py  --steps=300000              \\\n",
        "                  --scale=3                   \\\n",
        "                  --batch_size=128            \\\n",
        "                  --save-best-only=0          \\\n",
        "                  --save-every=1000           \\\n",
        "                  --save-log=0                \\\n",
        "                  --ckpt-dir=\"checkpoint/x3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wJAhH_XVIr9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df26101-8bc7-498c-80a5-e80fd481bd0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset/train/im_001.png\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "dataset/train/im_002.png\n",
            "dataset/train/im_003.png\n",
            "dataset/train/im_004.png\n",
            "dataset/train/im_005.png\n",
            "dataset/train/im_006.png\n",
            "dataset/train/im_007.png\n",
            "dataset/train/im_008.png\n",
            "dataset/train/im_009.png\n",
            "dataset/train/im_010.png\n",
            "dataset/train/im_011.png\n",
            "dataset/train/im_012.png\n",
            "dataset/train/im_013.png\n",
            "dataset/train/im_014.png\n",
            "dataset/train/im_015.png\n",
            "dataset/train/im_016.png\n",
            "dataset/train/im_017.png\n",
            "dataset/train/im_018.png\n",
            "dataset/train/im_019.png\n",
            "dataset/train/im_020.png\n",
            "dataset/train/im_021.png\n",
            "dataset/train/im_022.png\n",
            "dataset/train/im_023.png\n",
            "dataset/train/im_024.png\n",
            "dataset/train/im_025.png\n",
            "dataset/train/im_026.png\n",
            "dataset/train/im_027.png\n",
            "dataset/train/im_028.png\n",
            "dataset/train/im_029.png\n",
            "dataset/train/im_030.png\n",
            "dataset/train/im_031.png\n",
            "dataset/train/im_032.png\n",
            "dataset/train/im_033.png\n",
            "dataset/train/im_034.png\n",
            "dataset/train/im_035.png\n",
            "dataset/train/im_036.png\n",
            "dataset/train/im_037.png\n",
            "dataset/train/im_038.png\n",
            "dataset/train/im_039.png\n",
            "dataset/train/im_040.png\n",
            "dataset/train/im_041.png\n",
            "dataset/train/im_042.png\n",
            "dataset/train/im_043.png\n",
            "dataset/train/im_044.png\n",
            "dataset/train/im_045.png\n",
            "dataset/train/im_046.png\n",
            "dataset/train/im_047.png\n",
            "dataset/train/im_048.png\n",
            "dataset/train/im_049.png\n",
            "dataset/train/im_050.png\n",
            "dataset/train/im_051.png\n",
            "dataset/train/im_052.png\n",
            "dataset/train/im_053.png\n",
            "dataset/train/im_054.png\n",
            "dataset/train/im_055.png\n",
            "dataset/train/im_056.png\n",
            "dataset/train/im_057.png\n",
            "dataset/train/im_058.png\n",
            "dataset/train/im_059.png\n",
            "dataset/train/im_060.png\n",
            "dataset/train/im_061.png\n",
            "dataset/train/im_062.png\n",
            "dataset/train/im_063.png\n",
            "dataset/train/im_064.png\n",
            "dataset/train/im_065.png\n",
            "dataset/train/im_066.png\n",
            "dataset/train/im_067.png\n",
            "dataset/train/im_068.png\n",
            "dataset/train/im_069.png\n",
            "dataset/train/im_070.png\n",
            "dataset/train/im_071.png\n",
            "dataset/train/im_072.png\n",
            "dataset/train/im_073.png\n",
            "dataset/train/im_074.png\n",
            "dataset/train/im_075.png\n",
            "dataset/train/im_076.png\n",
            "dataset/train/im_077.png\n",
            "dataset/train/im_078.png\n",
            "dataset/train/im_079.png\n",
            "dataset/train/im_080.png\n",
            "dataset/train/im_081.png\n",
            "dataset/train/im_082.png\n",
            "dataset/train/im_083.png\n",
            "dataset/train/im_084.png\n",
            "dataset/train/im_085.png\n",
            "dataset/train/im_086.png\n",
            "dataset/train/im_087.png\n",
            "dataset/train/im_088.png\n",
            "dataset/train/im_089.png\n",
            "dataset/train/im_090.png\n",
            "dataset/train/im_091.png\n",
            "dataset/train/im_092.png\n",
            "dataset/train/im_093.png\n",
            "dataset/train/im_094.png\n",
            "dataset/train/im_095.png\n",
            "dataset/train/im_096.png\n",
            "dataset/train/im_097.png\n",
            "dataset/train/im_098.png\n",
            "dataset/train/im_099.png\n",
            "dataset/train/im_100.png\n",
            "dataset/train/t1.png\n",
            "dataset/train/t10.png\n",
            "dataset/train/t11.png\n",
            "dataset/train/t12.png\n",
            "dataset/train/t13.png\n",
            "dataset/train/t14.png\n",
            "dataset/train/t15.png\n",
            "dataset/train/t16.png\n",
            "dataset/train/t17.png\n",
            "dataset/train/t18.png\n",
            "dataset/train/t19.png\n",
            "dataset/train/t2.png\n",
            "dataset/train/t20.png\n",
            "dataset/train/t21.png\n",
            "dataset/train/t22.png\n",
            "dataset/train/t23.png\n",
            "dataset/train/t24.png\n",
            "dataset/train/t25.png\n",
            "dataset/train/t26.png\n",
            "dataset/train/t27.png\n",
            "dataset/train/t28.png\n",
            "dataset/train/t29.png\n",
            "dataset/train/t3.png\n",
            "dataset/train/t30.png\n",
            "dataset/train/t31.png\n",
            "dataset/train/t32.png\n",
            "dataset/train/t33.png\n",
            "dataset/train/t34.png\n",
            "dataset/train/t35.png\n",
            "dataset/train/t36.png\n",
            "dataset/train/t37.png\n",
            "dataset/train/t38.png\n",
            "dataset/train/t39.png\n",
            "dataset/train/t4.png\n",
            "dataset/train/t40.png\n",
            "dataset/train/t42.png\n",
            "dataset/train/t43.png\n",
            "dataset/train/t44.png\n",
            "dataset/train/t45.png\n",
            "dataset/train/t46.png\n",
            "dataset/train/t47.png\n",
            "dataset/train/t48.png\n",
            "dataset/train/t49.png\n",
            "dataset/train/t5.png\n",
            "dataset/train/t50.png\n",
            "dataset/train/t51.png\n",
            "dataset/train/t52.png\n",
            "dataset/train/t53.png\n",
            "dataset/train/t54.png\n",
            "dataset/train/t55.png\n",
            "dataset/train/t56.png\n",
            "dataset/train/t57.png\n",
            "dataset/train/t58.png\n",
            "dataset/train/t59.png\n",
            "dataset/train/t6.png\n",
            "dataset/train/t60.png\n",
            "dataset/train/t61.png\n",
            "dataset/train/t62.png\n",
            "dataset/train/t63.png\n",
            "dataset/train/t64.png\n",
            "dataset/train/t65.png\n",
            "dataset/train/t66.png\n",
            "dataset/train/t7.png\n",
            "dataset/train/t8.png\n",
            "dataset/train/t9.png\n",
            "dataset/train/tt1.png\n",
            "dataset/train/tt10.png\n",
            "dataset/train/tt12.png\n",
            "dataset/train/tt13.png\n",
            "dataset/train/tt14.png\n",
            "dataset/train/tt15.png\n",
            "dataset/train/tt16.png\n",
            "dataset/train/tt17.png\n",
            "dataset/train/tt18.png\n",
            "dataset/train/tt19.png\n",
            "dataset/train/tt2.png\n",
            "dataset/train/tt20.png\n",
            "dataset/train/tt21.png\n",
            "dataset/train/tt22.png\n",
            "dataset/train/tt23.png\n",
            "dataset/train/tt24.png\n",
            "dataset/train/tt25.png\n",
            "dataset/train/tt26.png\n",
            "dataset/train/tt27.png\n",
            "dataset/train/tt3.png\n",
            "dataset/train/tt4.png\n",
            "dataset/train/tt5.png\n",
            "dataset/train/tt6.png\n",
            "dataset/train/tt7.png\n",
            "dataset/train/tt8.png\n",
            "dataset/train/tt9.png\n",
            "dataset/validation/img_001_SRF_4_HR.png\n",
            "dataset/validation/img_002_SRF_4_HR.png\n",
            "dataset/validation/img_003_SRF_4_HR.png\n",
            "dataset/validation/img_004_SRF_4_HR.png\n",
            "dataset/validation/img_005_SRF_4_HR.png\n",
            "dataset/validation/img_006_SRF_4_HR.png\n",
            "dataset/validation/img_007_SRF_4_HR.png\n",
            "dataset/validation/img_008_SRF_4_HR.png\n",
            "dataset/validation/img_009_SRF_4_HR.png\n",
            "dataset/validation/img_010_SRF_4_HR.png\n",
            "dataset/validation/img_011_SRF_4_HR.png\n",
            "dataset/validation/img_012_SRF_4_HR.png\n",
            "dataset/validation/img_013_SRF_4_HR.png\n",
            "dataset/validation/img_014_SRF_4_HR.png\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ESPCN-Pytorch/train.py\", line 79, in <module>\n",
            "    main()\n",
            "  File \"/content/ESPCN-Pytorch/train.py\", line 74, in main\n",
            "    espcn.train(train_set, valid_set, steps=steps, batch_size=batch_size,\n",
            "  File \"/content/ESPCN-Pytorch/model.py\", line 93, in train\n",
            "    loss, metric = self.train_step(lr, hr)\n",
            "  File \"/content/ESPCN-Pytorch/model.py\", line 137, in train_step\n",
            "    sr = self.model(lr)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/ESPCN-Pytorch/neuralnet.py\", line 24, in forward\n",
            "    X = self.tanh(self.conv_1(X_in))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Train with scale x4\n",
        "!rm -rf dataset/*.npy\n",
        "!python train.py  --steps=300000              \\\n",
        "                  --scale=4                   \\\n",
        "                  --batch_size=128            \\\n",
        "                  --save-best-only=0          \\\n",
        "                  --save-every=1000           \\\n",
        "                  --save-log=0                \\\n",
        "                  --ckpt-dir=\"checkpoint/x4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhmsHWA94vSQ"
      },
      "source": [
        "# **Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG5oBG1T4vST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2f3064-5a30-4ada-fc23-33b5824a9ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38.84495544433594\n",
            "34.660394287109376\n",
            "32.064630126953126\n"
          ]
        }
      ],
      "source": [
        "# Test on Set5\n",
        "!python test.py --scale=2 --ckpt-path=\"default\"\n",
        "!python test.py --scale=3 --ckpt-path=\"default\"\n",
        "!python test.py --scale=4 --ckpt-path=\"default\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNMxCqEnIm5B"
      },
      "source": [
        "# **Demo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6LEod8iiyE2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484b3234-79f7-4b14-9544-7505ce94b110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!python demo.py --image-path=\"dataset/test1.png\" \\\n",
        "                --ckpt-path=\"default\"            \\\n",
        "                --scale=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXR3GIR_RumX"
      },
      "source": [
        "# **Dataset files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5PICMo-ThER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81049dce-c3e8-49ac-8dca-b43c1117b882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset-files.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile dataset-files.sh\n",
        "\n",
        "OPTION=$1\n",
        "DATASET_DIR=\"/content/ESPCN-Pytorch/dataset\"\n",
        "DRIVE_DIR=\"/content/drive/MyDrive/ESPCN-Pytorch\"\n",
        "SUBSETS=(\"train\" \"validation\" \"test\")\n",
        "TYPE=(\"data\" \"labels\")\n",
        "\n",
        "mkdir -p ${DRIVE_DIR}\n",
        "for type in ${TYPE[*]}; do\n",
        "    for subset in ${SUBSETS[*]}; do\n",
        "        # copy all generated dataset files to your drive\n",
        "        if [ \"$OPTION\" == \"copy to drive\" ]; then\n",
        "            cp -vf ${DATASET_DIR}/${type}_${subset}.npy ${DRIVE_DIR}\n",
        "\n",
        "        # copy all saved dataset files from your drive to dataset directory\n",
        "        elif [ \"$OPTION\" == \"copy from drive\" ]; then\n",
        "            cp -vf ${DRIVE_DIR}/${type}_${subset}.npy   ${DATASET_DIR}\n",
        "\n",
        "        # delete all generated dataset files in dataset directory\n",
        "        elif [ \"${OPTION}\" == \"remove\" ]; then\n",
        "            rm -vf ${DATASET_DIR}/${type}_${subset}.npy\n",
        "        fi\n",
        "    done\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n2cLVMYUDx3"
      },
      "outputs": [],
      "source": [
        "# !bash dataset-files.sh \"copy to drive\"\n",
        "# !bash dataset-files.sh \"copy from drive\"\n",
        "# !bash dataset-files.sh \"remove\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APDYH1_F6Rum"
      },
      "source": [
        "# **Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJu5zeBgtdDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9ec65a-6576-48a0-a42d-7ba7241ad5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ckpt.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile ckpt.sh\n",
        "OPTION=$1\n",
        "\n",
        "DRIVE_DIR=\"/content/drive/MyDrive/ESPCN-Pytorch\"\n",
        "SRC=\"/content/ESPCN-Pytorch/checkpoint\"\n",
        "DES=\"${DRIVE_DIR}/checkpoint\"\n",
        "SUBSETS=(\"x2\" \"x3\" \"x4\")\n",
        "\n",
        "mkdir -p ${DRIVE_DIR}\n",
        "for subset in ${SUBSETS[*]}; do\n",
        "    # remove all checkpoint files in sub-directories in checkpoint directory\n",
        "    if [ \"${OPTION}\" == \"remove\" ]; then\n",
        "        rm -vrf ${SRC}/${subset}\n",
        "        mkdir -p ${SRC}/${subset}\n",
        "\n",
        "    # copy all checkpoint directories to your drive\n",
        "    elif [ \"${OPTION}\" == \"copy to drive\" ]; then\n",
        "        mkdir -p ${DES}\n",
        "        mkdir -p ${DES}/${subset}\n",
        "        cp -vrf ${SRC}/${subset}/. ${DES}/${subset}\n",
        "\n",
        "    # copy all saved checkpoint files from your drive to checkpoint directory\n",
        "    elif [ \"${OPTION}\" == \"copy from drive\" ]; then\n",
        "        mkdir -p ${SRC}\n",
        "        mkdir -p ${SRC}/${subset}\n",
        "        cp -vrf ${DES}/${subset}/. ${SRC}/${subset}\n",
        "    fi\n",
        "\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3r9vXdj2pE3"
      },
      "outputs": [],
      "source": [
        "# !bash ckpt.sh \"copy from drive\"\n",
        "# !bash ckpt.sh \"copy to drive\"\n",
        "# !bash ckpt.sh \"remove\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}